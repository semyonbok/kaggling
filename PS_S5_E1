{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":85723,"databundleVersionId":10652996,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Let's go!\n## Imports and Set Up\n___","metadata":{}},{"cell_type":"code","source":"import warnings\nfrom pathlib import Path\nfrom copy import deepcopy  # probably unnecessary\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom joblib import Parallel, delayed\n\nfrom sklearn.base import (\n    BaseEstimator, TransformerMixin, RegressorMixin\n)\nfrom sklearn.compose import (\n    make_column_transformer, make_column_selector,\n)\n\nfrom sklearn.compose import (\n    make_column_transformer,\n    TransformedTargetRegressor\n)\nfrom sklearn.linear_model import (\n    ElasticNet, LinearRegression\n)\nfrom sklearn.metrics import (\n    mean_absolute_percentage_error,\n)\nfrom sklearn.model_selection import (\n    cross_val_predict, cross_val_score,\n    LeavePGroupsOut, TimeSeriesSplit,\n    GridSearchCV\n)\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import (\n    MinMaxScaler, OneHotEncoder,\n    OrdinalEncoder,\n    FunctionTransformer,\n    PolynomialFeatures\n)\nfrom sklearn.utils.validation import (\n    check_X_y, check_array, check_is_fitted\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:49:50.010639Z","iopub.execute_input":"2025-01-20T22:49:50.011022Z","iopub.status.idle":"2025-01-20T22:49:51.978555Z","shell.execute_reply.started":"2025-01-20T22:49:50.010943Z","shell.execute_reply":"2025-01-20T22:49:51.977212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\", category=FutureWarning)\n\npd.set_option(\"display.max_rows\", 500)\npd.set_option(\"display.max_columns\", 500)\n\nsns.set_style(\"ticks\")\n\nINPUT_PATH = Path.cwd().parents[1] / 'kaggle/input/playground-series-s5e1'\nTRAIN_PATH = INPUT_PATH / \"train.csv\"\nTEST_PATH = INPUT_PATH / \"test.csv\"\nSUB_PATH = INPUT_PATH / \"sample_submission.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:49:51.979866Z","iopub.execute_input":"2025-01-20T22:49:51.980426Z","iopub.status.idle":"2025-01-20T22:49:51.987130Z","shell.execute_reply.started":"2025-01-20T22:49:51.980392Z","shell.execute_reply":"2025-01-20T22:49:51.985521Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Markdown\n___\n**Observations** \n* Target has `int` dtype\n* Target contains `nan`s\n* Target distribution is positively skewed\n* Time-wise, *looks* like all test data occur after train data\n* No missing values, each entry corresponds to \"num_sold\" of a given product at the given shop in the given country (5 x 3 x 6 = 90 combinations)\n* Looks like evaluation metric does not account for missing values\n\n**Assumptions**\n* `nan` in target is equivalent to `0` (i.e., absence is due to lack of sales)\n* no hierarchical data\n\n**To Do**\n* [X] **EDA**\n    * [X] Confirm if test data contains same categories as train data\n* [ ] **FE**\n    * [ ] Time feature preprocessing\n    * [ ] Encode Christmas and other festive seasons in Western countries\n    * [ ] Country preprocessing: hemisphere, nordic or not?\n    * [ ] Bring basic country data\n    * [ ] Decide how to model iso week # (OneHot or Ordinal)\n    * [ ] Figure out how to apply rolling/lagging features\n* [ ] **Modelling**\n    * [ ] Tran without missing entries?\n    * [ ] Consider preprocessing target with `TransformedTargetRegressor`\n    * [ ] Use `TimeSeriesSplit` or `LeavePGroupsOut` for cross val\n    * [ ] Use a baseline model to compare\n    * [ ] Try an ensamble of linear models trained on different levels of grouping\n    * [ ] Use fallback estimator for `nan`s target\n    * [ ] Try an outlier-resistant linear model\n    * [ ] Try bayesian models?\n    * [X] Consider rounding predictions\n    * [ ] 90 linear models using one-hot encoded months, days(weekends?) and normalized years?","metadata":{"execution":{"iopub.status.busy":"2025-01-12T21:31:31.705668Z","iopub.execute_input":"2025-01-12T21:31:31.706154Z","iopub.status.idle":"2025-01-12T21:31:31.713287Z","shell.execute_reply.started":"2025-01-12T21:31:31.706107Z","shell.execute_reply":"2025-01-12T21:31:31.711662Z"}}},{"cell_type":"code","source":"X_data = pd.read_csv(TRAIN_PATH, index_col=\"date\", parse_dates=True)\nX_test = pd.read_csv(TEST_PATH, index_col=\"date\", parse_dates=True)\ny_test = pd.read_csv(SUB_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:49:51.988342Z","iopub.execute_input":"2025-01-20T22:49:51.988826Z","iopub.status.idle":"2025-01-20T22:49:52.627083Z","shell.execute_reply.started":"2025-01-20T22:49:51.988787Z","shell.execute_reply":"2025-01-20T22:49:52.625970Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = X_data.drop(columns=[\"id\", \"num_sold\"]).copy()\nX_test.drop(columns=\"id\", inplace=True)\n\ny_train = X_data[\"num_sold\"].copy()\ny_train.fillna(1, inplace=True) ## fill with ones to allow log","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:49:52.629136Z","iopub.execute_input":"2025-01-20T22:49:52.629509Z","iopub.status.idle":"2025-01-20T22:49:52.656097Z","shell.execute_reply.started":"2025-01-20T22:49:52.629481Z","shell.execute_reply":"2025-01-20T22:49:52.655071Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## EDA\n___\n### dtype, nunique, notnulls","metadata":{}},{"cell_type":"code","source":"info_df = (\n    pd.DataFrame(\n        [\n            X_train.dtypes,\n            X_train.nunique(),\n            X_train.notnull().sum(axis=0)\n        ],\n        index=[\"dtype\", \"nunique\", \"not_null\"]\n    )\n    .T\n    .sort_values(\"nunique\", ascending=False)\n)\ninfo_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:49:52.657595Z","iopub.execute_input":"2025-01-20T22:49:52.657928Z","iopub.status.idle":"2025-01-20T22:49:52.746595Z","shell.execute_reply.started":"2025-01-20T22:49:52.657902Z","shell.execute_reply":"2025-01-20T22:49:52.745334Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Categories","metadata":{}},{"cell_type":"code","source":"cat_cols = [\"country\", \"store\", \"product\"]\n(\n    X_data\n    .groupby(cat_cols)[\"num_sold\"]\n    .count()\n    .to_frame()\n    .T\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:49:52.747836Z","iopub.execute_input":"2025-01-20T22:49:52.748220Z","iopub.status.idle":"2025-01-20T22:49:52.859934Z","shell.execute_reply.started":"2025-01-20T22:49:52.748184Z","shell.execute_reply":"2025-01-20T22:49:52.858774Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Target","metadata":{}},{"cell_type":"code","source":"y_train.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:49:52.860850Z","iopub.execute_input":"2025-01-20T22:49:52.861142Z","iopub.status.idle":"2025-01-20T22:49:52.884193Z","shell.execute_reply.started":"2025-01-20T22:49:52.861116Z","shell.execute_reply":"2025-01-20T22:49:52.883039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 4, figsize=(16,3), tight_layout=True)\nsns.histplot(\n    y_train,\n    binrange=(0,6000),\n    binwidth=100,\n    ax=axes[0]\n);\nsns.histplot(\n    y_train[y_train <= 100],\n    discrete=True,\n    # binwidth=,\n    ax=axes[1]\n);\nsns.histplot(\n    y_train[y_train > 100],\n    binrange=(100,5940),\n    binwidth=10,\n    ax=axes[2]\n);\nsns.histplot(\n    np.log(y_train[y_train > 0]),\n    # binrange=(100,5940),\n    # binwidth=10,\n    ax=axes[3]\n);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:49:52.885285Z","iopub.execute_input":"2025-01-20T22:49:52.885643Z","iopub.status.idle":"2025-01-20T22:49:55.982242Z","shell.execute_reply.started":"2025-01-20T22:49:52.885595Z","shell.execute_reply":"2025-01-20T22:49:55.980509Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def yearly_line_plot(data, color=None):\n    resample = data.resample(\"Y\")\n    palette = sns.color_palette(\n         \"Blues\", n_colors=resample.ngroups\n    )\n    shift = 0\n    for i, (y, df) in enumerate(resample):\n        sns.lineplot(\n            df[\"num_sold\"].shift(shift, freq=\"D\"),\n            color=palette[i],\n            label=y.year\n        )\n        shift -= df.index.nunique()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:49:55.983330Z","iopub.execute_input":"2025-01-20T22:49:55.983656Z","iopub.status.idle":"2025-01-20T22:49:55.990520Z","shell.execute_reply.started":"2025-01-20T22:49:55.983631Z","shell.execute_reply":"2025-01-20T22:49:55.988994Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    for country in X_data[\"country\"].unique():\n        q_ = (\n            f\"(country =='{country}')\"\n            # \"and (store == 'Stickers for Less')\"\n            # \"and (product == 'Kaggle')\"\n        )\n        \n        g = sns.FacetGrid(\n            X_data.query(q_),\n            row=\"product\",\n            col=\"store\",\n            aspect=4,\n            height=2\n        );\n        g.map_dataframe(yearly_line_plot)\n        g.add_legend();\n        g.figure.suptitle(country, y=1.025)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:49:55.991837Z","iopub.execute_input":"2025-01-20T22:49:55.992282Z","iopub.status.idle":"2025-01-20T22:51:05.417718Z","shell.execute_reply.started":"2025-01-20T22:49:55.992243Z","shell.execute_reply":"2025-01-20T22:51:05.416183Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Missing Target","metadata":{}},{"cell_type":"code","source":"X_data[X_data[\"num_sold\"].isna()].groupby(cat_cols).size()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:51:05.419224Z","iopub.execute_input":"2025-01-20T22:51:05.419803Z","iopub.status.idle":"2025-01-20T22:51:05.442384Z","shell.execute_reply.started":"2025-01-20T22:51:05.419747Z","shell.execute_reply":"2025-01-20T22:51:05.441152Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def yearly_heatmap(data, **heatmap_kws):\n    pre_heat_df = pd.DataFrame(\n        np.array([\n            data.index.dayofyear,\n            data.index.year,\n            data[\"num_sold\"]\n        ]).T,\n        columns=[\"dayofyear\", \"year\", \"num_sold\"]\n    )\n    heat_df = (\n        pre_heat_df\n        .pivot_table(\n            columns=\"dayofyear\", index=\"year\", aggfunc=np.sum\n        )\n        .replace(0.0, np.nan)\n        .droplevel(0, axis=1)\n    )\n    heat_df.index = heat_df.index.astype(int)\n    heat_df.columns = heat_df.columns.astype(int)\n\n    sns.heatmap(\n        heat_df,\n        **heatmap_kws\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:51:05.443635Z","iopub.execute_input":"2025-01-20T22:51:05.444070Z","iopub.status.idle":"2025-01-20T22:51:05.450789Z","shell.execute_reply.started":"2025-01-20T22:51:05.444035Z","shell.execute_reply":"2025-01-20T22:51:05.449642Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# if RUN_SLOW_CELLS:\nfor country in [\"Canada\", \"Kenya\"]:\n    q_ = (\n        f\"(country =='{country}')\"\n        \"and (store != 'Discount Stickers')\"\n        \"and (product == 'Holographic Goose')\"\n    )\n    \n    g = sns.FacetGrid(\n        X_data.query(q_),\n        # col=\"country\",\n        row=\"store\",\n        aspect=8,\n        height=2\n    );\n    g.map_dataframe(\n        yearly_heatmap,\n        vmin=X_data.query(q_)[\"num_sold\"].min(),\n        vmax=X_data.query(q_)[\"num_sold\"].max(),\n        cbar=False,\n        lw=0.005,\n        linecolor=\"k\"\n    )\n    g.add_legend();\n    g.figure.suptitle(country, y=1.025)\n    g.figure.colorbar(\n        g.figure.axes[0].collections[0],\n        ax=g.figure.axes,\n        orientation='vertical',\n        aspect=100,\n        fraction=0.025,\n        pad=0.01\n    );\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:51:05.455253Z","iopub.execute_input":"2025-01-20T22:51:05.455627Z","iopub.status.idle":"2025-01-20T22:51:10.546887Z","shell.execute_reply.started":"2025-01-20T22:51:05.455599Z","shell.execute_reply":"2025-01-20T22:51:10.545576Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mean_absolute_percentage_error(y_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:51:10.549119Z","iopub.execute_input":"2025-01-20T22:51:10.549471Z","iopub.status.idle":"2025-01-20T22:51:10.560160Z","shell.execute_reply.started":"2025-01-20T22:51:10.549442Z","shell.execute_reply":"2025-01-20T22:51:10.558644Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## FE\n___","metadata":{}},{"cell_type":"code","source":"def transform_date(df):\n    return np.array(\n        [\n            # df.index.year,  # ordinal\n            df.index.quarter,\n            df.index.month,\n            # df.index.isocalendar().week,\n            df.index.dayofweek,\n            df.index.dayofweek > 4,  # weekend\n        ]\n    ).T\n\nnames_out = [\n    \"quarter\",\n    \"month\",\n    # \"iso_week\",\n    \"dayofweek\",\n    \"weekend\"\n]\n\ndate_tr = FunctionTransformer(\n    transform_date,\n    feature_names_out = lambda self, names_in: names_out \n)\ndate_tr.set_output(transform=\"pandas\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:51:10.561787Z","iopub.execute_input":"2025-01-20T22:51:10.562210Z","iopub.status.idle":"2025-01-20T22:51:10.586885Z","shell.execute_reply.started":"2025-01-20T22:51:10.562181Z","shell.execute_reply":"2025-01-20T22:51:10.585679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"date_ohe =  OneHotEncoder(drop=\"first\", sparse_output=False)\ndate_pl = make_pipeline(date_tr, date_ohe)\ndate_pl.fit_transform(X_train).shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:51:10.588035Z","iopub.execute_input":"2025-01-20T22:51:10.588378Z","iopub.status.idle":"2025-01-20T22:51:10.839626Z","shell.execute_reply.started":"2025-01-20T22:51:10.588340Z","shell.execute_reply":"2025-01-20T22:51:10.838290Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def transform_year(df):\n    return np.array(\n        [\n            df.index.year,\n            # df.index.isocalendar().week,\n        ]\n    ).T\n\nyear_tr = FunctionTransformer(\n    transform_year,\n    feature_names_out = lambda self, names_in: [\"year\"],\n)\nyear_tr.set_output(transform=\"pandas\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:51:10.841128Z","iopub.execute_input":"2025-01-20T22:51:10.841594Z","iopub.status.idle":"2025-01-20T22:51:10.851415Z","shell.execute_reply.started":"2025-01-20T22:51:10.841553Z","shell.execute_reply":"2025-01-20T22:51:10.850077Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"year_pl = make_pipeline(\n    year_tr,\n    PolynomialFeatures(\n        degree=3, include_bias=False,\n    ), MinMaxScaler()\n)\nyear_pl.fit_transform(X_train).shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:51:10.852444Z","iopub.execute_input":"2025-01-20T22:51:10.852754Z","iopub.status.idle":"2025-01-20T22:51:10.915570Z","shell.execute_reply.started":"2025-01-20T22:51:10.852728Z","shell.execute_reply":"2025-01-20T22:51:10.914349Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pre_proc = make_column_transformer(\n    (OrdinalEncoder(dtype=int), cat_cols),  # for grouping by\n    (year_pl, cat_cols),\n    (date_pl, cat_cols),\n)\npre_proc.set_output(transform=\"pandas\")\nX_train_pp = pre_proc.fit_transform(X_train)\nX_test_pp = pre_proc.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:51:10.916716Z","iopub.execute_input":"2025-01-20T22:51:10.917118Z","iopub.status.idle":"2025-01-20T22:51:11.665186Z","shell.execute_reply.started":"2025-01-20T22:51:10.917079Z","shell.execute_reply":"2025-01-20T22:51:11.663814Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Modelling\n___","metadata":{}},{"cell_type":"code","source":"# draft implementation\nclass GroupRegression(BaseEstimator, RegressorMixin):\n    def __init__(\n        self,\n        groupby_cols:list,\n        base_estimator=None,\n        **base_estimator_kws\n    ):\n        self.groupby_cols = groupby_cols\n        if base_estimator is None:\n            self.base_estimator = ElasticNet(**base_estimator_kws)\n        else:\n            self.base_estimator = base_estimator\n\n    def fit(self, X, y):\n        # X, y = check_X_y(X, y)\n\n        if not isinstance(X, pd.DataFrame):\n            X = pd.DataFrame(X)\n            \n        if not isinstance(y, pd.Series):\n            y = pd.Series(y)\n\n        X.reset_index(inplace=True, drop=True)\n        y.index = X.index\n        self.n_features_in_ = X.shape[1]\n        \n        for col in self.groupby_cols:\n            if col not in X.columns:\n                raise KeyError(\n                    f\"X does not contain the column for grouping: {col}\"\n                )\n\n        self.estimators_ = {}\n        for group, df in X.groupby(self.groupby_cols):\n            estimator = deepcopy(self.base_estimator)\n            estimator.fit(\n                df.drop(columns=self.groupby_cols),\n                y.loc[df.index]\n            )\n            self.estimators_[group] = estimator\n        \n        return self\n\n    def predict(self, X):\n        check_is_fitted(self, 'estimators_')\n        if not isinstance(X, pd.DataFrame):\n            X = pd.DataFrame(X)\n\n        X.reset_index(inplace=True, drop=True)\n        \n        for col in self.groupby_cols:\n            if col not in X.columns:\n                raise KeyError(\n                    f\"X does not contain the column for grouping: {col}\"\n                )\n        \n        y_pred = np.zeros(X.shape[0])\n        for group, df in X.groupby(self.groupby_cols):\n            y_pred[df.index] = self.estimators_[group].predict(\n                df.drop(columns=self.groupby_cols)\n            )\n        return y_pred.round()\n            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:51:11.666420Z","iopub.execute_input":"2025-01-20T22:51:11.666730Z","iopub.status.idle":"2025-01-20T22:51:11.677378Z","shell.execute_reply.started":"2025-01-20T22:51:11.666704Z","shell.execute_reply":"2025-01-20T22:51:11.676120Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GroupRegression(BaseEstimator, RegressorMixin):\n    \"\"\"\n    A scikit-learn style estimator that fits separate regression models \n    for each unique combination of categorical columns (groupby_cols).\n    \n    Parameters\n    ----------\n    groupby_cols : list\n        The column names in X to use for grouping. A separate model will \n        be fit for each unique combination of these columns.\n\n    base_estimator : estimator (default=None)\n        The base regressor to be cloned and fit for each group. If None, \n        defaults to sklearn's ElasticNet.\n\n    fallback_estimator : estimator (default=None)\n        An optional regressor trained on the entire dataset. If specified,\n        it is used for:\n          - groups with fewer than `min_samples` entries\n          - any unseen groups at prediction time.\n        If None, no fallback is used.\n\n    min_samples : int (default=5)\n        Minimum number of samples required to fit a group-specific model.\n        Groups with fewer samples will not have a specialized model \n        (they will use fallback, if defined).\n\n    use_rounding : bool (default=False)\n        Whether to round predictions to the nearest integer during `predict`.\n\n    n_jobs : int (default=1)\n        Number of CPU cores used for parallelizing the group-wise fitting.\n        If 1, no parallelism is used.\n\n    **base_estimator_kws : dict\n        Additional keyword arguments passed to the base_estimator if it is None.\n    \"\"\"\n    def __init__(\n        self,\n        groupby_cols,\n        base_estimator=None,\n        fallback_estimator=None,\n        min_samples=5,\n        use_rounding=False,\n        n_jobs=1,\n        **base_estimator_kws\n    ):\n        self.groupby_cols = groupby_cols\n        self.base_estimator = base_estimator\n        self.fallback_estimator = fallback_estimator\n        self.min_samples = min_samples\n        self.use_rounding = use_rounding\n        self.n_jobs = n_jobs\n        self.base_estimator_kws = base_estimator_kws\n\n    def fit(self, X, y):\n        \"\"\"\n        Fit separate estimators for each group, plus optionally a fallback.\n        \"\"\"\n        # Convert to DataFrame (required for groupby) and Series\n        # Allow object/categorical columns by specifying dtype=None\n        check_X_y(X, y, dtype=None)\n        X = pd.DataFrame(X)\n        y = pd.Series(y, index=X.index)\n\n        # Check grouping columns exist\n        for col in self.groupby_cols:\n            if col not in X.columns:\n                raise KeyError(f\"X does not contain the grouping column: {col}\")\n\n        # Reset index to ensure groupby won't lose alignment\n        X.reset_index(drop=True, inplace=True)\n        y.index = X.index\n        \n        self.n_features_in_ = X.shape[1] - len(self.groupby_cols)\n        self.estimators_ = {}\n        self.small_groups_ = []  # track groups under min_samples\n        self.groups_ = set()     # track groups that get specialized models\n\n        # Optionally train fallback on entire dataset (excluding groupby cols)\n        if self.fallback_estimator is not None:\n            self.fallback_model_ = deepcopy(self.fallback_estimator)\n        else:\n            self.fallback_model_ = None\n\n        if self.fallback_model_ is not None:\n            # Fit fallback on the entire dataset\n            X_fallback = X.drop(columns=self.groupby_cols)\n            self.fallback_model_.fit(X_fallback, y)\n\n        # Prepare data splits by group\n        grouped = X.groupby(self.groupby_cols)\n\n        # We'll define a helper function to fit one group\n        def fit_one_group(group_key, df):\n            # If group is too small, return None\n            if len(df) < self.min_samples:\n                return (group_key, None)\n            # Otherwise, clone base_estimator\n            if self.base_estimator is None:\n                estimator = ElasticNet(**self.base_estimator_kws)\n            else:\n                estimator = deepcopy(self.base_estimator)\n            # Fit specialized model on group\n            X_local = df.drop(columns=self.groupby_cols)\n            y_local = y.loc[df.index]\n            estimator.fit(X_local, y_local)\n            return (group_key, estimator)\n\n        # Either parallel or sequential\n        results = Parallel(n_jobs=self.n_jobs)(\n            delayed(fit_one_group)(g, df) for g, df in grouped\n        )\n\n        for group_key, estimator in results:\n            if estimator is None:\n                # group was too small\n                self.small_groups_.append(group_key)\n            else:\n                self.estimators_[group_key] = estimator\n                self.groups_.add(group_key)\n\n        return self\n\n    def predict(self, X):\n        \"\"\" \n        Predict using the group-specific model if available, otherwise fallback\n        or default. \n        \"\"\"\n        check_is_fitted(self, ['estimators_', 'groups_'])\n\n        # Convert X to DataFrame\n        X = pd.DataFrame(X)\n        # We'll skip strict check_X_y because we only do inference\n        X.reset_index(drop=True, inplace=True)\n\n        # Check grouping columns exist\n        for col in self.groupby_cols:\n            if col not in X.columns:\n                raise KeyError(f\"X does not contain the grouping column: {col}\")\n\n        # Prepare predictions\n        y_pred = np.zeros(X.shape[0], dtype=float)\n\n        # Group X by the same columns\n        grouped = X.groupby(self.groupby_cols)\n\n        # We can do a local function for group predict\n        def predict_one_group(group_key, df):\n            if group_key in self.estimators_:\n                estimator = self.estimators_[group_key]\n                return estimator.predict(df.drop(columns=self.groupby_cols))\n            else:\n                # If no specialized model, check fallback\n                if self.fallback_model_ is not None:\n                    return self.fallback_model_.predict(df.drop(columns=self.groupby_cols))\n                else:\n                    # return defaults for Holohoose in Kenya and Canada\n                    default = np.zeros(len(df), dtype=float) * 5\n                    if \"Canada\" in group_key:\n                        default = np.zeros(len(df), dtype=float) * 5\n                    return default\n\n        # Loop or parallel predict\n        for g, df in grouped:\n            idx = df.index\n            y_pred[idx] = predict_one_group(g, df)\n\n        if self.use_rounding:\n            y_pred = np.round(y_pred)\n\n        return y_pred\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:51:11.678378Z","iopub.execute_input":"2025-01-20T22:51:11.678711Z","iopub.status.idle":"2025-01-20T22:51:11.699670Z","shell.execute_reply.started":"2025-01-20T22:51:11.678683Z","shell.execute_reply":"2025-01-20T22:51:11.698547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" groupby_cols = [\n    \"ordinalencoder__country\",\n    \"ordinalencoder__store\",\n    \"ordinalencoder__product\"\n]\n\ngr = GroupRegression(groupby_cols, use_rounding=False, n_jobs=-1, alpha=.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:51:11.700778Z","iopub.execute_input":"2025-01-20T22:51:11.701207Z","iopub.status.idle":"2025-01-20T22:51:11.726847Z","shell.execute_reply.started":"2025-01-20T22:51:11.701169Z","shell.execute_reply":"2025-01-20T22:51:11.725696Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Validation 1","metadata":{}},{"cell_type":"code","source":"notnull_mask = X_data[\"num_sold\"].notnull()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:13:35.290043Z","iopub.execute_input":"2025-01-20T23:13:35.290564Z","iopub.status.idle":"2025-01-20T23:13:35.298145Z","shell.execute_reply.started":"2025-01-20T23:13:35.290523Z","shell.execute_reply":"2025-01-20T23:13:35.296532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# \"2010\":\"2014\"\ngr.fit(\n    X_train_pp.loc[notnull_mask].loc[\"2010\":\"2014\"],\n    y_train.loc[notnull_mask].loc[\"2010\":\"2014\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:13:35.850919Z","iopub.execute_input":"2025-01-20T23:13:35.851399Z","iopub.status.idle":"2025-01-20T23:13:38.663667Z","shell.execute_reply.started":"2025-01-20T23:13:35.851358Z","shell.execute_reply":"2025-01-20T23:13:38.662191Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = gr.predict(X_train_pp[notnull_mask].loc[\"2015\":])\ny_true = y_train[notnull_mask].loc[\"2015\":]\nmean_absolute_percentage_error(y_true, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:13:38.879509Z","iopub.execute_input":"2025-01-20T23:13:38.879906Z","iopub.status.idle":"2025-01-20T23:13:39.361532Z","shell.execute_reply.started":"2025-01-20T23:13:38.879876Z","shell.execute_reply":"2025-01-20T23:13:39.359170Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Validation 2","metadata":{}},{"cell_type":"code","source":"def custom_time_splits(X, notnull_mask=None, train_on_null=True):\n    \"\"\"\n    Generate 5 time-based splits:\n      - Train = 3 years\n      - Validation = 0.5 year\n      - Test = 1.5 years\n    Each split is shifted by 0.5 year from the previous split.\n\n    Returns:\n      An iterator of (train_idx, val_idx, test_idx) tuples.\n    \"\"\"\n\n    # The earliest date in the dataset\n    min_date = X.index[0]\n\n    if notnull_mask is None:\n        notnull_mask = pd.Series([True] * X.shape[0])\n\n    # We'll define lengths in months:\n    train_months = 36   # 3 years\n    val_months   = 6    # 0.5 year\n    test_months  = 18   # 1.5 years\n    shift_months = 6    # shift each split by 0.5 year\n\n    # We'll produce 4 splits total\n    for i in range(5):\n        # Compute start/end boundaries for each window\n        train_start = min_date + pd.DateOffset(months=shift_months * i)\n        train_end   = train_start + pd.DateOffset(months=train_months)\n\n        val_start   = train_end\n        val_end     = val_start + pd.DateOffset(months=val_months)\n\n        test_start  = val_end\n        test_end    = test_start + pd.DateOffset(months=test_months)\n\n        # Create boolean masks\n        train_mask = (X.index >= train_start) & (X.index < train_end)\n        if not train_on_null:\n            train_mask &= notnull_mask\n        val_mask   = (X.index >= val_start)   & (X.index < val_end) & notnull_mask\n        test_mask  = (X.index >= test_start)  & (X.index < test_end) & notnull_mask\n\n        # Convert masks to integer indices\n        train_idx = np.where(train_mask)[0]\n        val_idx   = np.where(val_mask)[0]\n        test_idx  = np.where(test_mask)[0]\n\n        yield (train_idx, val_idx, test_idx)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:51:15.561088Z","iopub.execute_input":"2025-01-20T22:51:15.561434Z","iopub.status.idle":"2025-01-20T22:51:15.584085Z","shell.execute_reply.started":"2025-01-20T22:51:15.561402Z","shell.execute_reply":"2025-01-20T22:51:15.581845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_time_splits(\n    X, y, splitter, model_factory,\n    metric=mean_absolute_percentage_error\n):\n    \"\"\"\n    Iterates over time-based splits, trains a model for each split,\n    logs train/validation/test scores, and returns a results DataFrame.\n    \"\"\"\n    cv_records = []\n    \n    for i, (train_idx, val_idx, test_idx) in enumerate(splitter, start=1):\n        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n        X_val,   y_val   = X.iloc[val_idx],   y.iloc[val_idx]\n        X_test,  y_test  = X.iloc[test_idx],  y.iloc[test_idx]\n\n        model = model_factory()\n        model.fit(X_train, y_train)\n\n        train_score = metric(y_train, model.predict(X_train))\n        val_score   = metric(y_val,   model.predict(X_val))\n        test_score  = metric(y_test,  model.predict(X_test))\n\n        cv_records.append({\n            'split': i,\n            'train_score': train_score,\n            'val_score': val_score,\n            'test_score': test_score\n        })\n    \n    results_df = pd.DataFrame(cv_records)\n    # for col in [\"train_score\", \"val_score\", \"\"]\n    return results_df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:51:15.585759Z","iopub.execute_input":"2025-01-20T22:51:15.586168Z","iopub.status.idle":"2025-01-20T22:51:15.625512Z","shell.execute_reply.started":"2025-01-20T22:51:15.586131Z","shell.execute_reply":"2025-01-20T22:51:15.622615Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"splitter_ = custom_time_splits(\n    X_train_pp,\n    notnull_mask=notnull_mask,\n    train_on_null=True\n)\nresults_df = evaluate_time_splits(\n    X_train_pp, y_train, splitter_,\n    lambda: deepcopy(gr)\n)\nresults_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:51:15.628545Z","iopub.execute_input":"2025-01-20T22:51:15.629317Z","iopub.status.idle":"2025-01-20T22:51:24.746264Z","shell.execute_reply.started":"2025-01-20T22:51:15.629275Z","shell.execute_reply":"2025-01-20T22:51:24.743948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df.mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:51:24.748234Z","iopub.execute_input":"2025-01-20T22:51:24.748678Z","iopub.status.idle":"2025-01-20T22:51:24.772753Z","shell.execute_reply.started":"2025-01-20T22:51:24.748631Z","shell.execute_reply":"2025-01-20T22:51:24.770402Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Diagnostics\n___","metadata":{}},{"cell_type":"code","source":"fig, ax =plt.subplots(figsize=(16,9))\ndf = pd.DataFrame(\n    [e.coef_ for e in gr.estimators_.values()],\n    index=gr.estimators_.keys(),\n    columns=X_train_pp.columns[3:]\n)\nsns.heatmap(df, ax=ax, cmap=\"Spectral_r\", center=0);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:51:24.775040Z","iopub.execute_input":"2025-01-20T22:51:24.775508Z","iopub.status.idle":"2025-01-20T22:51:25.695151Z","shell.execute_reply.started":"2025-01-20T22:51:24.775463Z","shell.execute_reply":"2025-01-20T22:51:25.693481Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"maep_ = abs(y_true - y_pred) / y_true\nmaep_.hist();","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:13:48.357274Z","iopub.execute_input":"2025-01-20T23:13:48.357652Z","iopub.status.idle":"2025-01-20T23:13:48.668278Z","shell.execute_reply.started":"2025-01-20T23:13:48.357623Z","shell.execute_reply":"2025-01-20T23:13:48.667003Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def yearly_maep_heatmap(data, **heatmap_kws):\n    pre_heat_df = pd.DataFrame(\n        np.array([\n            data.index.dayofyear,\n            data.index.year,\n            data[\"maep\"]\n        ]).T,\n        columns=[\"dayofyear\", \"year\", \"maep\"]\n    )\n    heat_df = (\n        pre_heat_df\n        .pivot_table(\n            columns=\"dayofyear\", index=\"year\", aggfunc=np.mean\n        )\n        # .replace(0.0, np.nan)\n        .droplevel(0, axis=1)\n    )\n    heat_df.index = heat_df.index.astype(int)\n    heat_df.columns = heat_df.columns.astype(int)\n\n    sns.heatmap(\n        heat_df,\n        **heatmap_kws\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:18:11.145507Z","iopub.execute_input":"2025-01-20T23:18:11.145908Z","iopub.status.idle":"2025-01-20T23:18:11.152943Z","shell.execute_reply.started":"2025-01-20T23:18:11.145876Z","shell.execute_reply":"2025-01-20T23:18:11.151358Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# if RUN_SLOW_CELLS:\nfor country in [\"Canada\", \"Kenya\"]:\n    q_ = (\n        f\"(country =='{country}')\"\n        # \"and (store != 'Discount Stickers')\"\n        # \"and (product == 'Holographic Goose')\"\n    )\n    data = (\n        X_data[notnull_mask]\n        .loc[\"2015\":]\n        .assign(maep=maep_.values)\n        .query(q_)\n    )\n    g = sns.FacetGrid(\n        data,\n        col=\"store\",\n        row=\"product\",\n        aspect=8,\n        height=2\n    );\n    g.map_dataframe(\n        yearly_maep_heatmap,\n        vmin=data[\"maep\"].min(),\n        vmax=data[\"maep\"].max(),\n        cbar=False,\n        lw=0.005,\n        linecolor=\"k\"\n    )\n    g.add_legend();\n    g.figure.suptitle(country, y=1.025)\n    g.figure.colorbar(\n        g.figure.axes[0].collections[0],\n        ax=g.figure.axes,\n        orientation='vertical',\n        aspect=100,\n        fraction=0.025,\n        pad=0.01\n    );\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:20:49.437034Z","iopub.execute_input":"2025-01-20T23:20:49.437519Z","iopub.status.idle":"2025-01-20T23:21:42.946954Z","shell.execute_reply.started":"2025-01-20T23:20:49.437460Z","shell.execute_reply":"2025-01-20T23:21:42.945692Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Submission\n___","metadata":{}},{"cell_type":"code","source":"gr.fit(X_train_pp.loc[notnull_mask], y_train.loc[notnull_mask])\ny_test[\"num_sold\"] = gr.predict(X_test_pp)\ny_test.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:51:26.009628Z","iopub.execute_input":"2025-01-20T22:51:26.009907Z","iopub.status.idle":"2025-01-20T22:51:27.600951Z","shell.execute_reply.started":"2025-01-20T22:51:26.009881Z","shell.execute_reply":"2025-01-20T22:51:27.599891Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
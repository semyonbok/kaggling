{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":34377,"databundleVersionId":3220602,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# (not yet) Kerasing Spacetanic","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-success\" role=\"alert\">\n  <strong>SCORE: </strong>0.8009\n</div>","metadata":{}},{"cell_type":"markdown","source":"## Inputs and Set-up","metadata":{}},{"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n# from tensorflow import keras\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder,\\\n    StandardScaler, MinMaxScaler, FunctionTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import make_column_selector, ColumnTransformer\n\nsns.set_theme(style=\"ticks\")","metadata":{"execution":{"iopub.execute_input":"2023-06-11T13:15:42.406652Z","iopub.status.busy":"2023-06-11T13:15:42.406245Z","iopub.status.idle":"2023-06-11T13:15:44.186312Z","shell.execute_reply":"2023-06-11T13:15:44.185144Z","shell.execute_reply.started":"2023-06-11T13:15:42.406620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_paths = []\nfor dirname, _, filenames in os.walk('data'):  # /kaggle/input\n    for filename in filenames:\n        file_paths.append(os.path.join(dirname, filename))\nfile_paths","metadata":{"execution":{"iopub.execute_input":"2023-06-11T13:15:44.188689Z","iopub.status.busy":"2023-06-11T13:15:44.188376Z","iopub.status.idle":"2023-06-11T13:15:44.198450Z","shell.execute_reply":"2023-06-11T13:15:44.197411Z","shell.execute_reply.started":"2023-06-11T13:15:44.188662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv(file_paths[0])\ntrain_data = pd.read_csv(file_paths[1])\ntrain_target = train_data[\"Transported\"].astype(int)\ntrain_data.drop(columns=\"Transported\", inplace=True)","metadata":{"execution":{"iopub.execute_input":"2023-06-11T13:15:44.200235Z","iopub.status.busy":"2023-06-11T13:15:44.199728Z","iopub.status.idle":"2023-06-11T13:15:44.322361Z","shell.execute_reply":"2023-06-11T13:15:44.321228Z","shell.execute_reply.started":"2023-06-11T13:15:44.200205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.execute_input":"2023-06-11T13:15:44.325725Z","iopub.status.busy":"2023-06-11T13:15:44.325358Z","iopub.status.idle":"2023-06-11T13:15:44.367715Z","shell.execute_reply":"2023-06-11T13:15:44.366615Z","shell.execute_reply.started":"2023-06-11T13:15:44.325693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are missing values, hence some imputation is in order. Since new `object` features will be introduced, imputation should follow feature creation.","metadata":{}},{"cell_type":"markdown","source":"## Categorical Feature Review and some Feature Engineering","metadata":{}},{"cell_type":"code","source":"train_data.loc[:,train_data.dtypes==object].nunique()","metadata":{"execution":{"iopub.execute_input":"2023-06-11T13:15:44.370534Z","iopub.status.busy":"2023-06-11T13:15:44.369130Z","iopub.status.idle":"2023-06-11T13:15:44.395348Z","shell.execute_reply":"2023-06-11T13:15:44.394230Z","shell.execute_reply.started":"2023-06-11T13:15:44.370490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For `object` columns with a handful of unique entries, one-hot/ordinal encoder will do straight away. `object` columns with numerous unique entries ought to be invesitgated for new feature creation.","metadata":{}},{"cell_type":"markdown","source":"### PassengerId, Cabin, Name?","metadata":{}},{"cell_type":"code","source":"train_data[[\"PassengerId\", \"Cabin\", \"Name\"]].sample(5)","metadata":{"execution":{"iopub.execute_input":"2023-06-11T13:15:44.397740Z","iopub.status.busy":"2023-06-11T13:15:44.396819Z","iopub.status.idle":"2023-06-11T13:15:44.421960Z","shell.execute_reply":"2023-06-11T13:15:44.420886Z","shell.execute_reply.started":"2023-06-11T13:15:44.397702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's define a custom Let's define a custom data preprocessor that splits the input feature on the specified separator string (e.g., \"_\" or \" \") and returns `n` new features, where `n` is the number of elements obtained with the split. It should handle the missing values, but return an error if there are varying number of elements in the splitted input feature. Optionally, it should be able to convert the obtained new features to numerical type.","metadata":{}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.utils.validation import check_is_fitted, check_array","metadata":{"execution":{"iopub.execute_input":"2023-06-11T13:15:44.423564Z","iopub.status.busy":"2023-06-11T13:15:44.423231Z","iopub.status.idle":"2023-06-11T13:15:44.428681Z","shell.execute_reply":"2023-06-11T13:15:44.427600Z","shell.execute_reply.started":"2023-06-11T13:15:44.423536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.values[:,[1]]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Splitter(BaseEstimator, TransformerMixin):\n    def __init__(self, sep=\"_\"):\n        self.sep = sep\n\n    def fit(self, X, y=None):\n        assert X.shape[1] == 1, \\\n            \"\\nX must be a 2-D array with one column.\"\n        *_, nonnan_entry_length = self._split(X)\n        self.n_features_out_ = nonnan_entry_length.unique()[0]\n        if hasattr(X, \"columns\"):\n            self.feature_names_in_ = X.columns.values[0]\n        else:\n            self.feature_names_in_ = \"\"\n        return self\n\n    def transform(self, X, convert_to_float=True):\n        check_is_fitted(self)\n        nan_mask, X_split, nonnan_entry_length = self._split(X)\n        assert nonnan_entry_length.unique()[0] == self.n_features_out_, \\\n            f\"\\nSplit with '{self.sep}' yields different n of features than seen in `fit`.\"\n\n        out = np.tile(np.array(np.nan, dtype=object), (len(X), self.n_features_out_))\n        out[~nan_mask] = np.vstack(X_split[~nan_mask])\n\n        if convert_to_float:\n            try:\n                out = out.astype(float)\n            except ValueError:  # encounter a string\n                pass\n\n        return out\n    \n    def inverse_transform(self, X):\n        check_is_fitted(self)\n        pass\n\n    def get_feature_names_out(self, names=None):\n        check_is_fitted(self)\n        if hasattr(self, \"feature_names_in_\"):\n            return [f\"{self.feature_names_in_}_S{i}\" for i in range(self.n_features_out_)]\n        else:\n            return [f\"S{i}\" for i in range(self.n_features_out_)]\n\n    def _split(self, X):\n        X = check_array(X, dtype=str, force_all_finite=\"allow-nan\")\n        nan_mask = (X.ravel() == \"nan\")\n        X_split = pd.Series(X.ravel()).str.split(self.sep).values\n        nonnan_entry_length = pd.Series(X_split[~nan_mask]).apply(len)\n\n        assert nonnan_entry_length.nunique() == 1, \\\n            f\"\\nSplit with '{self.sep}' yields varying n of features per entry.\"\n\n        return nan_mask, X_split, nonnan_entry_length","metadata":{"execution":{"iopub.execute_input":"2023-06-11T13:15:45.174110Z","iopub.status.busy":"2023-06-11T13:15:45.173682Z","iopub.status.idle":"2023-06-11T13:15:45.191013Z","shell.execute_reply":"2023-06-11T13:15:45.189745Z","shell.execute_reply.started":"2023-06-11T13:15:45.174078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_arrays = [\n    np.array([[\"3/3/4\"], [\"A/77/3\"], [np.nan]]),  # to be used in `fit`\n    np.array([[\"3/34\"], [\"A/222\"]]),  # fewer features\n    np.array([[\"3/3/4\"], [\"A/222_3\"]]),  # varying number of features\n]\n\ntest = Splitter(\"/\")\ntest.fit(pd.DataFrame(test_arrays[0], columns=[\"feature\"]))\nprint(test.n_features_out_)\nprint(test.feature_names_in_)\nprint(test.get_feature_names_out())\n\nfor i, t in enumerate(test_arrays):\n    try:\n        print(\"Test\", i)\n        print(test.transform(t, sparse_output=False))\n    except AssertionError:\n        print(\"Fail\")\n        continue","metadata":{"execution":{"iopub.execute_input":"2023-06-11T13:15:45.194008Z","iopub.status.busy":"2023-06-11T13:15:45.193626Z","iopub.status.idle":"2023-06-11T13:15:45.214977Z","shell.execute_reply":"2023-06-11T13:15:45.213807Z","shell.execute_reply.started":"2023-06-11T13:15:45.193977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### HomePlanet, CryoSleep, Destination, VIP","metadata":{}},{"cell_type":"code","source":"train_data[[\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\"]].sample(5)","metadata":{"execution":{"iopub.execute_input":"2023-06-11T13:15:45.217019Z","iopub.status.busy":"2023-06-11T13:15:45.216168Z","iopub.status.idle":"2023-06-11T13:15:45.234033Z","shell.execute_reply":"2023-06-11T13:15:45.232888Z","shell.execute_reply.started":"2023-06-11T13:15:45.216988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\"HomePlanet\" and \"Destination\" ought to be one-hot-encoded, whereas \"CryoSleep\" and \"VIP\" columns can be converted straight to 1s and 0s (whilst retaining `nan`s).","metadata":{}},{"cell_type":"code","source":"Floater = FunctionTransformer(lambda x: x.astype(float), feature_names_out=\"one-to-one\")","metadata":{"execution":{"iopub.execute_input":"2023-06-11T13:15:45.237094Z","iopub.status.busy":"2023-06-11T13:15:45.236632Z","iopub.status.idle":"2023-06-11T13:15:45.245453Z","shell.execute_reply":"2023-06-11T13:15:45.244201Z","shell.execute_reply.started":"2023-06-11T13:15:45.237064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = Floater.transform(train_data[[\"CryoSleep\"]])\nt[-10:]","metadata":{"execution":{"iopub.execute_input":"2023-06-11T13:15:45.248258Z","iopub.status.busy":"2023-06-11T13:15:45.247516Z","iopub.status.idle":"2023-06-11T13:15:45.266179Z","shell.execute_reply":"2023-06-11T13:15:45.264918Z","shell.execute_reply.started":"2023-06-11T13:15:45.248214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Numerical Feature Review and some more Feature Engineering","metadata":{}},{"cell_type":"code","source":"num_cols = train_data.loc[:,train_data.dtypes!=object].columns.values\nprint(train_data[num_cols].nunique(), \"\\n\")\ntrain_data[num_cols].describe()","metadata":{"execution":{"iopub.execute_input":"2023-06-11T13:42:16.105246Z","iopub.status.busy":"2023-06-11T13:42:16.104479Z","iopub.status.idle":"2023-06-11T13:42:16.116205Z","shell.execute_reply":"2023-06-11T13:42:16.115383Z","shell.execute_reply.started":"2023-06-11T13:42:16.105209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = MinMaxScaler().fit_transform(train_data[num_cols])\ndf = pd.DataFrame(df, columns=num_cols)\ndf.plot(\n    kind=\"hist\", subplots=True, layout=(-1,2), figsize=(18,6),\n    sharex=False, sharey=True, bins=50\n)","metadata":{"execution":{"iopub.execute_input":"2023-06-11T13:29:21.546620Z","iopub.status.busy":"2023-06-11T13:29:21.546172Z","iopub.status.idle":"2023-06-11T13:30:06.303045Z","shell.execute_reply":"2023-06-11T13:30:06.301905Z","shell.execute_reply.started":"2023-06-11T13:29:21.546586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It appears that the the distributions for all numerical columns but `Age` are significantly skewed. Because of that, we will feed the log of the original values to the model (while retaining `np.nan`s and zeros). Looks like most of values is zero. It would be useful to check if non-zero subsets are multi-modal or not.","metadata":{"execution":{"iopub.execute_input":"2023-06-11T13:42:43.389257Z","iopub.status.busy":"2023-06-11T13:42:43.388838Z","iopub.status.idle":"2023-06-11T13:42:43.748860Z","shell.execute_reply":"2023-06-11T13:42:43.747591Z","shell.execute_reply.started":"2023-06-11T13:42:43.389224Z"},"trusted":true}},{"cell_type":"code","source":"df = pd.DataFrame(index=train_data.index.copy())\nfor col in num_cols:\n    cond = train_data[col] > 0  # to filter out zeros (and nans)\n    df = df.join(train_data.loc[cond, col] )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = MinMaxScaler().fit_transform(df)\ndf = pd.DataFrame(df, columns=num_cols)\ndf.plot(\n    kind=\"hist\", subplots=True, layout=(-1,2), figsize=(18,6),\n    sharex=False, sharey=True, bins=50,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The log transformer below will not only find the log of values greater than zero, but also retain the original missing values. This will enable further imputation.","metadata":{}},{"cell_type":"code","source":"def find_log(x):\n    out = np.where(x > 0, np.log(x, where=x > 0), 0.0)\n    out = np.where(np.isnan(x), np.nan, out)\n    return out\n\nLoggaformer = FunctionTransformer(find_log, feature_names_out=\"one-to-one\")\n# Loggaformer = FunctionTransformer(lambda x: np.where(x > 1e-6, np.log(x), 0.0))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"markdown","source":"The custom `Splitter` preprocessor can palusably output columns containing `objects` rather than numerical data which can cause the upcast of all new feautures to `object`. That is suboptimal. Upon a few attempts to do some post-processessing within the `Splitter` guts, I decided it would be easier instead to use two `ColumnTransofrmer`s. <br><br>Since I intend to chain two `ColumnTansformers`, I don't see how it can work without the upstream transformer ouputiting `pd.Dataframe`. Hence, I am changing the `sklearn` config to ouput dataframes rathen than `numpy` arrays.","metadata":{}},{"cell_type":"code","source":"from sklearn import set_config\nset_config(transform_output=\"pandas\", display='diagram') ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OneHotPipeline = Pipeline([\n    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"encode\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n])\n\nLogPipeline = Pipeline([\n    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"encode\", Loggaformer),\n    (\"scale\", MinMaxScaler(feature_range=(-1,1)))\n])\n\nFloatPipeline = Pipeline([\n    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"encode\", Floater),\n    (\"scale\", MinMaxScaler(feature_range=(-1,1)))\n])\n\nSplitPipeline = Pipeline([\n    (\"split\", Splitter(sep=\"/|_\")),\n    # *OneHotPipeline.steps\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PreProc = ColumnTransformer([\n    (\"Id\", SplitPipeline, [\"PassengerId\"]),\n    (\"Cabin\", SplitPipeline, [\"Cabin\"]),\n    (\"OneHot\", OneHotPipeline, [\"HomePlanet\", \"Destination\"]),\n    (\"Float\", FloatPipeline, [\"CryoSleep\", \"VIP\", \"Age\"]),\n    (\"Log\", LogPipeline, num_cols[num_cols != \"Age\"]),   \n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = pd.DataFrame(\n#     PreProc.fit_transform(train_data),\n#     columns=PreProc.get_feature_names_out()\n# )\ndf = PreProc.fit_transform(train_data)\ndf.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PostProc = ColumnTransformer([\n    (\"CabinImpute\", OneHotPipeline, [\"Cabin__Cabin_S0\", \"Cabin__Cabin_S2\"]),\n], remainder=FloatPipeline)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = PostProc.fit_transform(df)\ndf1.info()","metadata":{"execution":{"iopub.execute_input":"2022-07-17T18:49:35.280088Z","iopub.status.busy":"2022-07-17T18:49:35.279684Z","iopub.status.idle":"2022-07-17T18:49:35.302931Z","shell.execute_reply":"2022-07-17T18:49:35.302222Z","shell.execute_reply.started":"2022-07-17T18:49:35.280056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.hist(layout=(-1,3), figsize=(12,27))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sklearn Model","metadata":{}},{"cell_type":"markdown","source":"Things to try before moving on to Keras:\n* stratified sampling\n* more complex imputation\n* XGBoost?\n* Demonstrate expected model performance with nested cross-validation\n* Examine correlation of engineered features with the  target\n* spell check","metadata":{}},{"cell_type":"code","source":"from scipy.stats import geom, uniform, randint\n\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import cross_val_score, KFold, GridSearchCV, RandomizedSearchCV\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mainline = Pipeline([\n    (\"US\", PreProc),  # upstream\n    (\"DS\", PostProc),  # downstream\n    (\"Model\", GradientBoostingClassifier())\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mainline.fit(train_data, train_target)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CV = KFold(n_splits=5, shuffle=True, random_state=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = cross_val_score(mainline, train_data, train_target, scoring=\"accuracy\", cv=CV, n_jobs=-1)\npd.Series(scores).describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series(geom(1/100, 100).rvs(1000000)).value_counts().sort_index()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mainline[\"Model\"].get_params()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_distributions = {\n    \"Model__n_estimators\": geom(1/100, 100),\n    \"Model__learning_rate\": uniform(0,1),\n    \"Model__max_depth\": randint(1, 11),\n    \"Model__min_samples_split\": randint(2, 11),\n    \"Model__min_samples_leaf\": randint(1, 11),\n    \"Model__max_features\": uniform(0.5,.5),\n    \"Model__subsample\": uniform(.5, .5),\n}\n\nmodel_random_search = RandomizedSearchCV(\n    mainline,\n    param_distributions=param_distributions,\n    n_iter=1000,\n    cv=CV,\n    verbose=1,\n    n_jobs=-2\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_random_search.fit(train_data, train_target)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_random_search.best_params_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mainline.set_params(**model_random_search.best_params_)\nscores = cross_val_score(mainline, train_data, train_target, scoring=\"accuracy\", cv=CV, n_jobs=-1)\npd.Series(scores).describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"column_results = [f\"param_{name}\" for name in param_distributions.keys()]\ncolumn_results += [\"mean_test_score\", \"std_test_score\", \"rank_test_score\"]\n\ncv_results = pd.DataFrame(model_random_search.cv_results_)\ncv_results = cv_results[column_results].sort_values(\n    \"mean_test_score\", ascending=False\n)\n\n\ndef shorten_param(param_name):\n    if \"__\" in param_name:\n        return param_name.rsplit(\"__\", 1)[1]\n    return param_name\n\n\ncv_results = cv_results.rename(shorten_param, axis=1)\ncv_results.to_csv(\"cv_results.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now use the grid search around the best parameters found with RandomSearch","metadata":{}},{"cell_type":"code","source":"param_grid  = {\n    \"Model__n_estimators\": [140,150,160],\n    \"Model__learning_rate\": [0.116, 0.117, 0.118],\n    \"Model__max_depth\": [3,4,5],\n    \"Model__min_samples_split\": [5,6,7],\n    \"Model__min_samples_leaf\": [2,3,4],\n    \"Model__max_features\": [27/27, 26/27, 25/27],\n    \"Model__subsample\": [.65, .7, .75],\n}\n\nmodel_gird_search = GridSearchCV(\n    mainline,\n    param_grid =param_grid ,\n    cv=CV,\n    verbose=1,\n    n_jobs=-2\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_gird_search.fit(train_data, train_target)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_gird_search.best_params_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mainline.set_params(**model_gird_search.best_params_)\nscores = cross_val_score(mainline, train_data, train_target, scoring=\"accuracy\", cv=CV, n_jobs=-1)\npd.Series(scores).describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_cv_results = pd.DataFrame(model_gird_search.cv_results_)\ngrid_cv_results = grid_cv_results[column_results].sort_values(\n    \"mean_test_score\", ascending=False\n)\n\ngrid_cv_results = grid_cv_results.rename(shorten_param, axis=1)\ngrid_cv_results.to_csv(\"grid_cv_results.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mainline.set_params(**{\"Model__n_iter_no_change\":75, \"Model__n_estimators\":500})\nscores = cross_val_score(mainline, train_data, train_target, scoring=\"accuracy\", cv=CV, n_jobs=-1)\npd.Series(scores).describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mainline.fit(train_data, train_target)\nsubmission = test_data[[\"PassengerId\"]].join(\n    pd.DataFrame(mainline.predict(test_data), columns=[\"Transported\"]).astype(bool))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"grad_boost_submit.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.join(train_target).corr().iloc[:,-1].sort_values()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n## Keras Model","metadata":{}},{"cell_type":"markdown","source":"Using functional API to build an unnecessarily big model. Adding dropout and Ridge regularization to tackle overfit.","metadata":{}},{"cell_type":"code","source":"passengers = keras.Input(shape=(train_data.shape[1],), name=\"passenger\")\n\nmid_layers = keras.layers.Dense(2048,\n                                kernel_regularizer= keras.regularizers.l2(0.003),\n                                activation=\"relu\")(passengers)\nmid_layers = keras.layers.Dropout(0.3)(mid_layers)\n\nmid_layers = keras.layers.Dense(2048,\n#                                 kernel_regularizer= keras.regularizers.l2(0.003),\n                                activation=\"relu\")(mid_layers)\n# mid_layers = keras.layers.Dropout(0.3)(mid_layers)\n\nmid_layers = keras.layers.Dense(2048,\n                                kernel_regularizer= keras.regularizers.l2(0.003),\n                                activation=\"relu\")(mid_layers)\nmid_layers = keras.layers.Dropout(0.3)(mid_layers)\n\n# mid_layers = keras.layers.Dense(1024,\n#                                 kernel_regularizer= keras.regularizers.l2(0.001),\n#                                 activation=\"relu\")(mid_layers)\n# mid_layers = keras.layers.Dropout(0.2)(mid_layers)\n\nvitals = keras.layers.Dense(1, activation=\"sigmoid\", name=\"vitals\")(mid_layers)","metadata":{"execution":{"iopub.execute_input":"2022-07-17T20:34:25.710429Z","iopub.status.busy":"2022-07-17T20:34:25.710009Z","iopub.status.idle":"2022-07-17T20:34:25.793682Z","shell.execute_reply":"2022-07-17T20:34:25.792701Z","shell.execute_reply.started":"2022-07-17T20:34:25.710394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Earlier, it was noted that validation loss starts to \"oscillate\" durling later epochs when the learning rate is high. Thus, defined a callback to reduce the rate every 10 epochs.","metadata":{}},{"cell_type":"code","source":"def scheduler(epoch, lr):\n    if (epoch > 0) & (epoch % 10 == 0):\n        return lr / 2\n    else:\n        return lr\ncallback = keras.callbacks.LearningRateScheduler(scheduler, 1)","metadata":{"execution":{"iopub.execute_input":"2022-07-17T20:34:27.615512Z","iopub.status.busy":"2022-07-17T20:34:27.613224Z","iopub.status.idle":"2022-07-17T20:34:27.621102Z","shell.execute_reply":"2022-07-17T20:34:27.620286Z","shell.execute_reply.started":"2022-07-17T20:34:27.615470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs_num = 60\nmodel = keras.Model(inputs=passengers, outputs=vitals)\n\nmodel.compile(\n    optimizer=keras.optimizers.RMSprop(1e-3),\n    loss=\"BinaryCrossentropy\", metrics=[\"accuracy\"])\n\nhistory = model.fit(\n    train_data, train_target, batch_size=4300, epochs=epochs_num,\n    validation_split=.25, shuffle=True, callbacks = [callback])","metadata":{"execution":{"iopub.execute_input":"2022-07-17T20:34:28.791565Z","iopub.status.busy":"2022-07-17T20:34:28.791110Z","iopub.status.idle":"2022-07-17T20:37:18.173547Z","shell.execute_reply":"2022-07-17T20:37:18.172243Z","shell.execute_reply.started":"2022-07-17T20:34:28.791527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for _ in range(5):\n    sample = train_data.sample(4000)\n    # train_target[sample.index]\n    model.evaluate(sample, train_target[sample.index])","metadata":{"execution":{"iopub.execute_input":"2022-07-17T20:39:23.295093Z","iopub.status.busy":"2022-07-17T20:39:23.294629Z","iopub.status.idle":"2022-07-17T20:39:32.070205Z","shell.execute_reply":"2022-07-17T20:39:32.069214Z","shell.execute_reply.started":"2022-07-17T20:39:23.295058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history[\"loss\"].copy()\nval_loss = history.history[\"val_loss\"].copy()\ng_loss = sns.lineplot(x = range(1, len(loss)+1), y=loss, label=\"Test\")\nsns.scatterplot(x = range(1, len(loss)+1), y=val_loss, ax=g_loss, label=\"Validation\")\ng_loss.set_ylim(0,1.5)\ng_loss.set_ylabel(\"Logistic Loss\")\ng_loss.set_xlabel(\"Batch No\")\ng_loss.set_xticks(range(0, epochs_num+10, 10))\ng_loss.grid(True, axis=\"x\")","metadata":{"execution":{"iopub.execute_input":"2022-07-17T20:39:57.212771Z","iopub.status.busy":"2022-07-17T20:39:57.212379Z","iopub.status.idle":"2022-07-17T20:39:57.459529Z","shell.execute_reply":"2022-07-17T20:39:57.458354Z","shell.execute_reply.started":"2022-07-17T20:39:57.212723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history[\"accuracy\"].copy()\nval_acc = history.history[\"val_accuracy\"].copy()\ng_acc = sns.lineplot(x = range(1, len(acc)+1), y=acc, label=\"Test\")\nsns.scatterplot(x = range(1, len(acc)+1), y=val_acc, ax=g_acc, label=\"Validation\")\ng_acc.set_ylim(0.5,1)\ng_acc.set_ylabel(\"Accuracy\")\ng_acc.set_xlabel(\"Batch No\")\ng_acc.set_xticks(range(0, epochs_num+10, 10))\ng_acc.grid(True, axis=\"x\")","metadata":{"execution":{"iopub.execute_input":"2022-07-17T20:40:02.437920Z","iopub.status.busy":"2022-07-17T20:40:02.437524Z","iopub.status.idle":"2022-07-17T20:40:02.679253Z","shell.execute_reply":"2022-07-17T20:40:02.678009Z","shell.execute_reply.started":"2022-07-17T20:40:02.437884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.execute_input":"2022-07-17T19:21:57.609566Z","iopub.status.busy":"2022-07-17T19:21:57.609143Z","iopub.status.idle":"2022-07-17T19:21:57.765706Z","shell.execute_reply":"2022-07-17T19:21:57.764373Z","shell.execute_reply.started":"2022-07-17T19:21:57.609526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"predict = model.predict(test_data)\npredict = pd.Series(predict.reshape(-1,))","metadata":{"execution":{"iopub.execute_input":"2022-07-17T20:40:19.722692Z","iopub.status.busy":"2022-07-17T20:40:19.722274Z","iopub.status.idle":"2022-07-17T20:40:21.878570Z","shell.execute_reply":"2022-07-17T20:40:21.877648Z","shell.execute_reply.started":"2022-07-17T20:40:19.722648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = predict.apply(lambda x: True if x>=.5 else False)\npredict.value_counts()","metadata":{"execution":{"iopub.execute_input":"2022-07-17T20:40:21.880596Z","iopub.status.busy":"2022-07-17T20:40:21.880024Z","iopub.status.idle":"2022-07-17T20:40:21.891314Z","shell.execute_reply":"2022-07-17T20:40:21.890195Z","shell.execute_reply.started":"2022-07-17T20:40:21.880566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv(\"/kaggle/input/spaceship-titanic/sample_submission.csv\")\nsubmit[\"Transported\"] = predict","metadata":{"execution":{"iopub.execute_input":"2022-07-17T20:40:22.783877Z","iopub.status.busy":"2022-07-17T20:40:22.783051Z","iopub.status.idle":"2022-07-17T20:40:22.803536Z","shell.execute_reply":"2022-07-17T20:40:22.802634Z","shell.execute_reply.started":"2022-07-17T20:40:22.783843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.to_csv(\"submission.csv\", index=False)\nsubmit","metadata":{"execution":{"iopub.execute_input":"2022-07-17T20:40:23.973662Z","iopub.status.busy":"2022-07-17T20:40:23.973031Z","iopub.status.idle":"2022-07-17T20:40:23.995997Z","shell.execute_reply":"2022-07-17T20:40:23.994836Z","shell.execute_reply.started":"2022-07-17T20:40:23.973626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"version10.keras\")","metadata":{"execution":{"iopub.execute_input":"2022-07-17T20:52:05.978458Z","iopub.status.busy":"2022-07-17T20:52:05.977713Z","iopub.status.idle":"2022-07-17T20:52:06.145623Z","shell.execute_reply":"2022-07-17T20:52:06.144073Z","shell.execute_reply.started":"2022-07-17T20:52:05.978405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
